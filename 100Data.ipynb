{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1emZ/FdpIcjJASiLuF+kL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saeidhoseinipour/100Data/blob/main/100Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydataset\n",
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6JO27guPUfw",
        "outputId": "3f16e001-1ea3-4d22-b20b-627b911e2bbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydataset\n",
            "  Downloading pydataset-0.2.0.tar.gz (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pydataset) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pydataset) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pydataset) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pydataset) (1.17.0)\n",
            "Building wheels for collected packages: pydataset\n",
            "  Building wheel for pydataset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydataset: filename=pydataset-0.2.0-py3-none-any.whl size=15939417 sha256=b4bdfe708ead782a6fa9e527c289698fb11edea431c48a7de449cc4edbb05067\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/3f/af54c413cecaac292940342c61882d2a8848674175d0bb0889\n",
            "Successfully built pydataset\n",
            "Installing collected packages: pydataset\n",
            "Successfully installed pydataset-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BXGFlB7OaaP",
        "outputId": "3ae7604b-65b8-4792-d0fa-3cc09604018d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Gene Expression Dataset:\n",
            "      gene  sample_0  sample_1  sample_2  sample_3  sample_4  sample_5  sample_6  sample_7  \\\n",
            "0  gene_0  0.771814  0.825179  0.048663  0.566476  0.760438  0.190926  0.866722  0.565902   \n",
            "1  gene_1  0.169331  0.106842  0.165393  0.606631  0.062212  0.518681  0.761699  0.417028   \n",
            "2  gene_2  0.811991  0.593594  0.395272  0.768286  0.516349  0.525414  0.241548  0.881177   \n",
            "3  gene_3  0.572478  0.690040  0.103846  0.078084  0.106014  0.180196  0.434550  0.692425   \n",
            "4  gene_4  0.873184  0.621802  0.396909  0.371167  0.242977  0.916439  0.050170  0.648201   \n",
            "\n",
            "   sample_8  ...  sample_10  sample_11  sample_12  sample_13  sample_14  sample_15  sample_16  \\\n",
            "0  0.074470  ...   0.387757   0.623801   0.041448   0.995097   0.115277   0.142609   0.795275   \n",
            "1  0.748868  ...   0.478421   0.117448   0.659518   0.749848   0.859487   0.487745   0.694591   \n",
            "2  0.037793  ...   0.566892   0.504087   0.989449   0.788174   0.403537   0.028092   0.011691   \n",
            "3  0.998204  ...   0.122148   0.087137   0.804503   0.141869   0.751586   0.452349   0.862461   \n",
            "4  0.169860  ...   0.859266   0.551280   0.950511   0.303612   0.001586   0.684409   0.191578   \n",
            "\n",
            "   sample_17  sample_18  sample_19  \n",
            "0   0.757787   0.777806   0.728148  \n",
            "1   0.740781   0.508025   0.202400  \n",
            "2   0.208599   0.880163   0.294841  \n",
            "3   0.463858   0.138019   0.074951  \n",
            "4   0.493250   0.321907   0.190827  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Dataset Type: quantitative\n",
            "Dataset Features: ['gene_0', 'gene_1', 'gene_2', 'gene_3', 'gene_4', 'gene_5', 'gene_6', 'gene_7', 'gene_8', 'gene_9', 'gene_10', 'gene_11', 'gene_12', 'gene_13', 'gene_14', 'gene_15', 'gene_16', 'gene_17', 'gene_18', 'gene_19', 'gene_20', 'gene_21', 'gene_22', 'gene_23', 'gene_24', 'gene_25', 'gene_26', 'gene_27', 'gene_28', 'gene_29', 'gene_30', 'gene_31', 'gene_32', 'gene_33', 'gene_34', 'gene_35', 'gene_36', 'gene_37', 'gene_38', 'gene_39', 'gene_40', 'gene_41', 'gene_42', 'gene_43', 'gene_44', 'gene_45', 'gene_46', 'gene_47', 'gene_48', 'gene_49', 'gene_50', 'gene_51', 'gene_52', 'gene_53', 'gene_54', 'gene_55', 'gene_56', 'gene_57', 'gene_58', 'gene_59', 'gene_60', 'gene_61', 'gene_62', 'gene_63', 'gene_64', 'gene_65', 'gene_66', 'gene_67', 'gene_68', 'gene_69', 'gene_70', 'gene_71', 'gene_72', 'gene_73', 'gene_74', 'gene_75', 'gene_76', 'gene_77', 'gene_78', 'gene_79', 'gene_80', 'gene_81', 'gene_82', 'gene_83', 'gene_84', 'gene_85', 'gene_86', 'gene_87', 'gene_88', 'gene_89', 'gene_90', 'gene_91', 'gene_92', 'gene_93', 'gene_94', 'gene_95', 'gene_96', 'gene_97', 'gene_98', 'gene_99', 'sample']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn.datasets import make_classification, load_diabetes, load_breast_cancer\n",
        "from pydataset import data\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class BioinformaticsDatasetCleaner:\n",
        "    def __init__(self, dataset_names=None):\n",
        "        \"\"\"\n",
        "        Initialize the class with a list of dataset names or use built-in datasets.\n",
        "        :param dataset_names: List of dataset filenames (e.g., ['data1.csv', 'data2.xlsx']).\n",
        "        \"\"\"\n",
        "        self.dataset_names = dataset_names\n",
        "        self.cleaned_datasets = {}\n",
        "        self.builtin_datasets = {\n",
        "            'titanic': {\n",
        "                'loader': self.load_titanic_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['class', 'age', 'sex', 'survived']\n",
        "            },\n",
        "            'cancer': {\n",
        "                'loader': self.load_cancer_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'target']\n",
        "            },\n",
        "            'synthetic': {\n",
        "                'loader': self.load_synthetic_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'feature_{i}' for i in range(10)] + ['target']\n",
        "            },\n",
        "            'diabetes': {\n",
        "                'loader': self.load_diabetes_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
        "            },\n",
        "            'iris': {\n",
        "                'loader': self.load_iris_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "            },\n",
        "            'tips': {\n",
        "                'loader': self.load_tips_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n",
        "            },\n",
        "            'flights': {\n",
        "                'loader': self.load_flights_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['year', 'month', 'passengers']\n",
        "            },\n",
        "            'mtcars': {\n",
        "                'loader': self.load_mtcars_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
        "            },\n",
        "            'diamonds': {\n",
        "                'loader': self.load_diamonds_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
        "            },\n",
        "            'sleep': {\n",
        "                'loader': self.load_sleep_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['extra', 'group', 'ID']\n",
        "            },\n",
        "            'gene_expression': {\n",
        "                'loader': self.load_gene_expression_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'gene_{i}' for i in range(100)] + ['sample']\n",
        "            },\n",
        "            'cell_cycle': {\n",
        "                'loader': self.load_cell_cycle_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['cell', 'phase']\n",
        "            },\n",
        "            'protein_interaction': {\n",
        "                'loader': self.load_protein_interaction_dataset,\n",
        "                'type': 'network',\n",
        "                'features': [f'protein_{i}' for i in range(10)]\n",
        "            },\n",
        "            'tcga_brca': {\n",
        "                'loader': self.load_tcga_brca_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'gene_{i}' for i in range(100)] + ['patient']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def read_dataset(self, dataset_name):\n",
        "        \"\"\"\n",
        "        Read a dataset based on its file extension or load a built-in dataset.\n",
        "        :param dataset_name: Name of the dataset file or built-in dataset.\n",
        "        :return: Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        if dataset_name in self.builtin_datasets:\n",
        "            logging.info(f\"Loading built-in dataset: {dataset_name}\")\n",
        "            return self.builtin_datasets[dataset_name]['loader']()\n",
        "        elif dataset_name.endswith('.csv'):\n",
        "            logging.info(f\"Reading CSV file: {dataset_name}\")\n",
        "            return pd.read_csv(dataset_name)\n",
        "        elif dataset_name.endswith('.xlsx') or dataset_name.endswith('.xls'):\n",
        "            logging.info(f\"Reading Excel file: {dataset_name}\")\n",
        "            return pd.read_excel(dataset_name)\n",
        "        elif dataset_name.endswith('.json'):\n",
        "            logging.info(f\"Reading JSON file: {dataset_name}\")\n",
        "            return pd.read_json(dataset_name)\n",
        "        elif dataset_name.endswith('.parquet'):\n",
        "            logging.info(f\"Reading Parquet file: {dataset_name}\")\n",
        "            return pd.read_parquet(dataset_name)\n",
        "        elif dataset_name.endswith('.dta'):\n",
        "            logging.info(f\"Reading Stata file: {dataset_name}\")\n",
        "            return pd.read_stata(dataset_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format or dataset: {dataset_name}\")\n",
        "\n",
        "    def clean_dataset(self, df):\n",
        "        \"\"\"\n",
        "        Clean a dataset by handling missing values, duplicates, and formatting.\n",
        "        :param df: Input Pandas DataFrame.\n",
        "        :return: Cleaned Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        logging.info(\"Cleaning dataset...\")\n",
        "        # Handle missing values\n",
        "        df.ffill(inplace=True)  # Forward fill missing values\n",
        "        df.bfill(inplace=True)  # Backward fill remaining missing values\n",
        "\n",
        "        # Remove duplicates\n",
        "        df.drop_duplicates(inplace=True)\n",
        "\n",
        "        # Convert columns to appropriate data types\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col])\n",
        "            except ValueError:\n",
        "                pass  # Ignore columns that cannot be converted to numeric\n",
        "\n",
        "        logging.info(\"Dataset cleaned successfully.\")\n",
        "        return df\n",
        "\n",
        "    def process_all_datasets(self):\n",
        "        \"\"\"\n",
        "        Process all datasets in the list.\n",
        "        :return: Dictionary of cleaned datasets with metadata.\n",
        "        \"\"\"\n",
        "        if self.dataset_names is None:\n",
        "            self.dataset_names = list(self.builtin_datasets.keys())\n",
        "\n",
        "        for dataset_name in self.dataset_names:\n",
        "            logging.info(f\"Processing dataset: {dataset_name}\")\n",
        "            df = self.read_dataset(dataset_name)\n",
        "            cleaned_df = self.clean_dataset(df)\n",
        "            self.cleaned_datasets[dataset_name] = {\n",
        "                'data': cleaned_df,\n",
        "                'type': self.builtin_datasets[dataset_name]['type'],\n",
        "                'features': self.builtin_datasets[dataset_name]['features']\n",
        "            }\n",
        "            logging.info(f\"Cleaned dataset: {dataset_name}\\n{cleaned_df.head()}\\n\")\n",
        "\n",
        "        return self.cleaned_datasets\n",
        "\n",
        "    def get_cleaned_dataset(self, dataset_name):\n",
        "        \"\"\"\n",
        "        Get a specific cleaned dataset by name.\n",
        "        :param dataset_name: Name of the dataset.\n",
        "        :return: Cleaned Pandas DataFrame, type, and features.\n",
        "        \"\"\"\n",
        "        if dataset_name in self.cleaned_datasets:\n",
        "            return self.cleaned_datasets[dataset_name]\n",
        "        else:\n",
        "            raise KeyError(f\"Dataset {dataset_name} not found in cleaned datasets.\")\n",
        "\n",
        "    # Built-in dataset loaders\n",
        "    def load_titanic_dataset(self):\n",
        "        \"\"\"Load the Titanic dataset from pydataset.\"\"\"\n",
        "        return data('titanic')\n",
        "\n",
        "    def load_cancer_dataset(self):\n",
        "        \"\"\"Load the Breast Cancer dataset from scikit-learn.\"\"\"\n",
        "        data = load_breast_cancer(as_frame=True)\n",
        "        return data.frame\n",
        "\n",
        "    def load_synthetic_dataset(self):\n",
        "        \"\"\"Generate a synthetic dataset for classification.\"\"\"\n",
        "        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
        "        return pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)]).assign(target=y)\n",
        "\n",
        "    def load_diabetes_dataset(self):\n",
        "        \"\"\"Load the Diabetes dataset from scikit-learn.\"\"\"\n",
        "        return load_diabetes(as_frame=True).frame\n",
        "\n",
        "    def load_iris_dataset(self):\n",
        "        \"\"\"Load the Iris dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('iris')\n",
        "\n",
        "    def load_tips_dataset(self):\n",
        "        \"\"\"Load the Tips dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('tips')\n",
        "\n",
        "    def load_flights_dataset(self):\n",
        "        \"\"\"Load the Flights dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('flights')\n",
        "\n",
        "    def load_mtcars_dataset(self):\n",
        "        \"\"\"Load the mtcars dataset from pydataset.\"\"\"\n",
        "        return data('mtcars')\n",
        "\n",
        "    def load_diamonds_dataset(self):\n",
        "        \"\"\"Load the Diamonds dataset from pydataset.\"\"\"\n",
        "        return data('diamonds')\n",
        "\n",
        "    def load_sleep_dataset(self):\n",
        "        \"\"\"Load the Sleep dataset from pydataset.\"\"\"\n",
        "        return data('sleep')\n",
        "\n",
        "    def load_gene_expression_dataset(self):\n",
        "        \"\"\"Load a synthetic gene expression dataset.\"\"\"\n",
        "        genes = [f'gene_{i}' for i in range(100)]\n",
        "        samples = [f'sample_{i}' for i in range(20)]\n",
        "        data = np.random.rand(100, 20)  # Random gene expression values\n",
        "        return pd.DataFrame(data, index=genes, columns=samples).reset_index().rename(columns={'index': 'gene'})\n",
        "\n",
        "    def load_cell_cycle_dataset(self):\n",
        "        \"\"\"Load a synthetic cell cycle dataset.\"\"\"\n",
        "        cells = [f'cell_{i}' for i in range(50)]\n",
        "        phases = ['G1', 'S', 'G2', 'M']\n",
        "        data = np.random.choice(phases, size=50)  # Random cell cycle phases\n",
        "        return pd.DataFrame({'cell': cells, 'phase': data})\n",
        "\n",
        "    def load_protein_interaction_dataset(self):\n",
        "        \"\"\"Load a synthetic protein-protein interaction dataset.\"\"\"\n",
        "        proteins = [f'protein_{i}' for i in range(10)]\n",
        "        interactions = np.random.randint(0, 2, size=(10, 10))  # Random binary interactions\n",
        "        return pd.DataFrame(interactions, index=proteins, columns=proteins).reset_index().rename(columns={'index': 'protein'})\n",
        "\n",
        "    def load_tcga_brca_dataset(self):\n",
        "        \"\"\"Load a synthetic TCGA BRCA dataset.\"\"\"\n",
        "        genes = [f'gene_{i}' for i in range(100)]\n",
        "        patients = [f'patient_{i}' for i in range(50)]\n",
        "        data = np.random.rand(100, 50)  # Random gene expression values\n",
        "        return pd.DataFrame(data, index=genes, columns=patients).reset_index().rename(columns={'index': 'gene'})\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the BioinformaticsDatasetCleaner class\n",
        "    cleaner = BioinformaticsDatasetCleaner()\n",
        "\n",
        "    # Process all built-in datasets\n",
        "    cleaned_datasets = cleaner.process_all_datasets()\n",
        "\n",
        "    # Access a specific cleaned dataset\n",
        "    cleaned_gene_expression = cleaner.get_cleaned_dataset('gene_expression')\n",
        "    print(\"Cleaned Gene Expression Dataset:\\n\", cleaned_gene_expression['data'].head())\n",
        "    print(\"Dataset Type:\", cleaned_gene_expression['type'])\n",
        "    print(\"Dataset Features:\", cleaned_gene_expression['features'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn.datasets import make_classification, load_diabetes, load_breast_cancer\n",
        "from pydataset import data\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class BioinformaticsDatasetCleaner:\n",
        "    def __init__(self, dataset_names=None):\n",
        "        \"\"\"\n",
        "        Initialize the class with a list of dataset names or use built-in datasets.\n",
        "        :param dataset_names: List of dataset filenames (e.g., ['data1.csv', 'data2.xlsx']).\n",
        "        \"\"\"\n",
        "        self.dataset_names = dataset_names\n",
        "        self.cleaned_datasets = {}\n",
        "        self.builtin_datasets = {\n",
        "            'titanic': {\n",
        "                'loader': self.load_titanic_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['class', 'age', 'sex', 'survived']\n",
        "            },\n",
        "            'cancer': {\n",
        "                'loader': self.load_cancer_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'target']\n",
        "            },\n",
        "            'synthetic': {\n",
        "                'loader': self.load_synthetic_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'feature_{i}' for i in range(10)] + ['target']\n",
        "            },\n",
        "            'diabetes': {\n",
        "                'loader': self.load_diabetes_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
        "            },\n",
        "            'iris': {\n",
        "                'loader': self.load_iris_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "            },\n",
        "            'tips': {\n",
        "                'loader': self.load_tips_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n",
        "            },\n",
        "            'flights': {\n",
        "                'loader': self.load_flights_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['year', 'month', 'passengers']\n",
        "            },\n",
        "            'mtcars': {\n",
        "                'loader': self.load_mtcars_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
        "            },\n",
        "            'diamonds': {\n",
        "                'loader': self.load_diamonds_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
        "            },\n",
        "            'sleep': {\n",
        "                'loader': self.load_sleep_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': ['extra', 'group', 'ID']\n",
        "            },\n",
        "            'gene_expression': {\n",
        "                'loader': self.load_gene_expression_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'gene_{i}' for i in range(100)] + ['sample']\n",
        "            },\n",
        "            'cell_cycle': {\n",
        "                'loader': self.load_cell_cycle_dataset,\n",
        "                'type': 'qualitative',\n",
        "                'features': ['cell', 'phase']\n",
        "            },\n",
        "            'protein_interaction': {\n",
        "                'loader': self.load_protein_interaction_dataset,\n",
        "                'type': 'network',\n",
        "                'features': [f'protein_{i}' for i in range(10)]\n",
        "            },\n",
        "            'tcga_brca': {\n",
        "                'loader': self.load_tcga_brca_dataset,\n",
        "                'type': 'quantitative',\n",
        "                'features': [f'gene_{i}' for i in range(100)] + ['patient']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def read_dataset(self, dataset_name):\n",
        "        \"\"\"\n",
        "        Read a dataset based on its file extension or load a built-in dataset.\n",
        "        :param dataset_name: Name of the dataset file or built-in dataset.\n",
        "        :return: Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        if dataset_name in self.builtin_datasets:\n",
        "            logging.info(f\"Loading built-in dataset: {dataset_name}\")\n",
        "            return self.builtin_datasets[dataset_name]['loader']()\n",
        "        elif dataset_name.endswith('.csv'):\n",
        "            logging.info(f\"Reading CSV file: {dataset_name}\")\n",
        "            return pd.read_csv(dataset_name)\n",
        "        elif dataset_name.endswith('.xlsx') or dataset_name.endswith('.xls'):\n",
        "            logging.info(f\"Reading Excel file: {dataset_name}\")\n",
        "            return pd.read_excel(dataset_name)\n",
        "        elif dataset_name.endswith('.json'):\n",
        "            logging.info(f\"Reading JSON file: {dataset_name}\")\n",
        "            return pd.read_json(dataset_name)\n",
        "        elif dataset_name.endswith('.parquet'):\n",
        "            logging.info(f\"Reading Parquet file: {dataset_name}\")\n",
        "            return pd.read_parquet(dataset_name)\n",
        "        elif dataset_name.endswith('.dta'):\n",
        "            logging.info(f\"Reading Stata file: {dataset_name}\")\n",
        "            return pd.read_stata(dataset_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format or dataset: {dataset_name}\")\n",
        "\n",
        "    def clean_dataset(self, df):\n",
        "        \"\"\"\n",
        "        Clean a dataset by handling missing values, duplicates, and formatting.\n",
        "        :param df: Input Pandas DataFrame.\n",
        "        :return: Cleaned Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        logging.info(\"Cleaning dataset...\")\n",
        "        # Handle missing values\n",
        "        df.ffill(inplace=True)  # Forward fill missing values\n",
        "        df.bfill(inplace=True)  # Backward fill remaining missing values\n",
        "\n",
        "        # Remove duplicates\n",
        "        df.drop_duplicates(inplace=True)\n",
        "\n",
        "        # Convert columns to appropriate data types\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col])\n",
        "            except ValueError:\n",
        "                pass  # Ignore columns that cannot be converted to numeric\n",
        "\n",
        "        logging.info(\"Dataset cleaned successfully.\")\n",
        "        return df\n",
        "\n",
        "    def process_all_datasets(self):\n",
        "        \"\"\"\n",
        "        Process all datasets in the list.\n",
        "        :return: Dictionary of cleaned datasets with metadata.\n",
        "        \"\"\"\n",
        "        if self.dataset_names is None:\n",
        "            self.dataset_names = list(self.builtin_datasets.keys())\n",
        "\n",
        "        for dataset_name in self.dataset_names:\n",
        "            logging.info(f\"Processing dataset: {dataset_name}\")\n",
        "            df = self.read_dataset(dataset_name)\n",
        "            cleaned_df = self.clean_dataset(df)\n",
        "            self.cleaned_datasets[dataset_name] = {\n",
        "                'data': cleaned_df,\n",
        "                'type': self.builtin_datasets[dataset_name]['type'],\n",
        "                'features': self.builtin_datasets[dataset_name]['features']\n",
        "            }\n",
        "            logging.info(f\"Cleaned dataset: {dataset_name}\\n{cleaned_df.head()}\\n\")\n",
        "\n",
        "        return self.cleaned_datasets\n",
        "\n",
        "    def get_all_datasets(self):\n",
        "        \"\"\"\n",
        "        Return all cleaned datasets in dictionary format.\n",
        "        :return: Dictionary of all cleaned datasets.\n",
        "        \"\"\"\n",
        "        return self.cleaned_datasets\n",
        "\n",
        "    # Built-in dataset loaders\n",
        "    def load_titanic_dataset(self):\n",
        "        \"\"\"Load the Titanic dataset from pydataset.\"\"\"\n",
        "        return data('titanic')\n",
        "\n",
        "    def load_cancer_dataset(self):\n",
        "        \"\"\"Load the Breast Cancer dataset from scikit-learn.\"\"\"\n",
        "        data = load_breast_cancer(as_frame=True)\n",
        "        return data.frame\n",
        "\n",
        "    def load_synthetic_dataset(self):\n",
        "        \"\"\"Generate a synthetic dataset for classification.\"\"\"\n",
        "        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
        "        return pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)]).assign(target=y)\n",
        "\n",
        "    def load_diabetes_dataset(self):\n",
        "        \"\"\"Load the Diabetes dataset from scikit-learn.\"\"\"\n",
        "        return load_diabetes(as_frame=True).frame\n",
        "\n",
        "    def load_iris_dataset(self):\n",
        "        \"\"\"Load the Iris dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('iris')\n",
        "\n",
        "    def load_tips_dataset(self):\n",
        "        \"\"\"Load the Tips dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('tips')\n",
        "\n",
        "    def load_flights_dataset(self):\n",
        "        \"\"\"Load the Flights dataset from seaborn.\"\"\"\n",
        "        return sns.load_dataset('flights')\n",
        "\n",
        "    def load_mtcars_dataset(self):\n",
        "        \"\"\"Load the mtcars dataset from pydataset.\"\"\"\n",
        "        return data('mtcars')\n",
        "\n",
        "    def load_diamonds_dataset(self):\n",
        "        \"\"\"Load the Diamonds dataset from pydataset.\"\"\"\n",
        "        return data('diamonds')\n",
        "\n",
        "    def load_sleep_dataset(self):\n",
        "        \"\"\"Load the Sleep dataset from pydataset.\"\"\"\n",
        "        return data('sleep')\n",
        "\n",
        "    def load_gene_expression_dataset(self):\n",
        "        \"\"\"Load a synthetic gene expression dataset.\"\"\"\n",
        "        genes = [f'gene_{i}' for i in range(100)]\n",
        "        samples = [f'sample_{i}' for i in range(20)]\n",
        "        data = np.random.rand(100, 20)  # Random gene expression values\n",
        "        return pd.DataFrame(data, index=genes, columns=samples).reset_index().rename(columns={'index': 'gene'})\n",
        "\n",
        "    def load_cell_cycle_dataset(self):\n",
        "        \"\"\"Load a synthetic cell cycle dataset.\"\"\"\n",
        "        cells = [f'cell_{i}' for i in range(50)]\n",
        "        phases = ['G1', 'S', 'G2', 'M']\n",
        "        data = np.random.choice(phases, size=50)  # Random cell cycle phases\n",
        "        return pd.DataFrame({'cell': cells, 'phase': data})\n",
        "\n",
        "    def load_protein_interaction_dataset(self):\n",
        "        \"\"\"Load a synthetic protein-protein interaction dataset.\"\"\"\n",
        "        proteins = [f'protein_{i}' for i in range(10)]\n",
        "        interactions = np.random.randint(0, 2, size=(10, 10))  # Random binary interactions\n",
        "        return pd.DataFrame(interactions, index=proteins, columns=proteins).reset_index().rename(columns={'index': 'protein'})\n",
        "\n",
        "    def load_tcga_brca_dataset(self):\n",
        "        \"\"\"Load a synthetic TCGA BRCA dataset.\"\"\"\n",
        "        genes = [f'gene_{i}' for i in range(100)]\n",
        "        patients = [f'patient_{i}' for i in range(50)]\n",
        "        data = np.random.rand(100, 50)  # Random gene expression values\n",
        "        return pd.DataFrame(data, index=genes, columns=patients).reset_index().rename(columns={'index': 'gene'})\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the BioinformaticsDatasetCleaner class\n",
        "    cleaner = BioinformaticsDatasetCleaner()\n",
        "\n",
        "    # Process all built-in datasets\n",
        "    cleaned_datasets = cleaner.process_all_datasets()\n",
        "\n",
        "    # Get all cleaned datasets in dictionary format\n",
        "    all_datasets = cleaner.get_all_datasets()\n",
        "\n",
        "    # Print all datasets in dictionary format\n",
        "    for dataset_name, dataset_info in all_datasets.items():\n",
        "        print(f\"Dataset: {dataset_name}\")\n",
        "        print(f\"Type: {dataset_info['type']}\")\n",
        "        print(f\"Features: {dataset_info['features']}\")\n",
        "        print(f\"Data:\\n{dataset_info['data'].head()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVwi4me4RSv2",
        "outputId": "6a9f67d9-2b16-4c1a-a47b-e38354463089"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: titanic\n",
            "Type: qualitative\n",
            "Features: ['class', 'age', 'sex', 'survived']\n",
            "Data:\n",
            "         class     age    sex survived\n",
            "1    1st class  adults    man      yes\n",
            "58   1st class  adults    man       no\n",
            "176  1st class  adults  women      yes\n",
            "316  1st class  adults  women       no\n",
            "320  1st class   child    man      yes\n",
            "\n",
            "Dataset: cancer\n",
            "Type: qualitative\n",
            "Features: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'target']\n",
            "Data:\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  mean compactness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840           0.27760   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474           0.07864   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960           0.15990   \n",
            "3        11.42         20.38           77.58      386.1          0.14250           0.28390   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030           0.13280   \n",
            "\n",
            "   mean concavity  mean concave points  mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
            "0          0.3001              0.14710         0.2419                 0.07871  ...          17.33   \n",
            "1          0.0869              0.07017         0.1812                 0.05667  ...          23.41   \n",
            "2          0.1974              0.12790         0.2069                 0.05999  ...          25.53   \n",
            "3          0.2414              0.10520         0.2597                 0.09744  ...          26.50   \n",
            "4          0.1980              0.10430         0.1809                 0.05883  ...          16.67   \n",
            "\n",
            "   worst perimeter  worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0           184.60      2019.0            0.1622             0.6656           0.7119   \n",
            "1           158.80      1956.0            0.1238             0.1866           0.2416   \n",
            "2           152.50      1709.0            0.1444             0.4245           0.4504   \n",
            "3            98.87       567.7            0.2098             0.8663           0.6869   \n",
            "4           152.20      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  target  \n",
            "0                0.2654          0.4601                  0.11890       0  \n",
            "1                0.1860          0.2750                  0.08902       0  \n",
            "2                0.2430          0.3613                  0.08758       0  \n",
            "3                0.2575          0.6638                  0.17300       0  \n",
            "4                0.1625          0.2364                  0.07678       0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Dataset: synthetic\n",
            "Type: quantitative\n",
            "Features: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'target']\n",
            "Data:\n",
            "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
            "0  -1.140526   1.359706   0.861991   0.846092   0.606010  -1.556629   1.754794   1.696456   \n",
            "1  -0.078734  -1.329332   0.627375  -1.193006  -0.773010   0.097676   0.497998   0.959271   \n",
            "2   0.807427   0.730198  -1.285680   0.889484  -1.804882  -0.763259   0.048085  -0.904317   \n",
            "3   0.588465  -0.375121  -0.575002  -0.149518  -0.563725   0.412931   0.243687  -0.506943   \n",
            "4   1.636312  -1.640607  -1.360456  -0.941163  -1.430141   1.632411   0.130741  -1.435862   \n",
            "\n",
            "   feature_8  feature_9  target  \n",
            "0  -1.280429  -2.081929       1  \n",
            "1   0.024510   1.451144       1  \n",
            "2  -1.627542   0.259723       0  \n",
            "3  -0.822220   0.244967       0  \n",
            "4  -0.440044   1.441273       0  \n",
            "\n",
            "Dataset: diabetes\n",
            "Type: quantitative\n",
            "Features: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
            "Data:\n",
            "        age       sex       bmi        bp        s1        s2        s3        s4        s5  \\\n",
            "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401 -0.002592  0.019907   \n",
            "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412 -0.039493 -0.068332   \n",
            "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356 -0.002592  0.002861   \n",
            "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038  0.034309  0.022688   \n",
            "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142 -0.002592 -0.031988   \n",
            "\n",
            "         s6  target  \n",
            "0 -0.017646   151.0  \n",
            "1 -0.092204    75.0  \n",
            "2 -0.025930   141.0  \n",
            "3 -0.009362   206.0  \n",
            "4 -0.046641   135.0  \n",
            "\n",
            "Dataset: iris\n",
            "Type: quantitative\n",
            "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
            "Data:\n",
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "Dataset: tips\n",
            "Type: quantitative\n",
            "Features: ['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n",
            "Data:\n",
            "   total_bill   tip     sex smoker  day    time  size\n",
            "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
            "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
            "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
            "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
            "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
            "\n",
            "Dataset: flights\n",
            "Type: quantitative\n",
            "Features: ['year', 'month', 'passengers']\n",
            "Data:\n",
            "   year month  passengers\n",
            "0  1949   Jan         112\n",
            "1  1949   Feb         118\n",
            "2  1949   Mar         132\n",
            "3  1949   Apr         129\n",
            "4  1949   May         121\n",
            "\n",
            "Dataset: mtcars\n",
            "Type: quantitative\n",
            "Features: ['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
            "Data:\n",
            "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
            "Mazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
            "Mazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
            "Datsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
            "Hornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
            "Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n",
            "\n",
            "Dataset: diamonds\n",
            "Type: quantitative\n",
            "Features: ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
            "Data:\n",
            "   carat      cut color clarity  depth  table  price     x     y     z\n",
            "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
            "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
            "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
            "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
            "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
            "\n",
            "Dataset: sleep\n",
            "Type: quantitative\n",
            "Features: ['extra', 'group', 'ID']\n",
            "Data:\n",
            "   extra  group  ID\n",
            "1    0.7      1   1\n",
            "2   -1.6      1   2\n",
            "3   -0.2      1   3\n",
            "4   -1.2      1   4\n",
            "5   -0.1      1   5\n",
            "\n",
            "Dataset: gene_expression\n",
            "Type: quantitative\n",
            "Features: ['gene_0', 'gene_1', 'gene_2', 'gene_3', 'gene_4', 'gene_5', 'gene_6', 'gene_7', 'gene_8', 'gene_9', 'gene_10', 'gene_11', 'gene_12', 'gene_13', 'gene_14', 'gene_15', 'gene_16', 'gene_17', 'gene_18', 'gene_19', 'gene_20', 'gene_21', 'gene_22', 'gene_23', 'gene_24', 'gene_25', 'gene_26', 'gene_27', 'gene_28', 'gene_29', 'gene_30', 'gene_31', 'gene_32', 'gene_33', 'gene_34', 'gene_35', 'gene_36', 'gene_37', 'gene_38', 'gene_39', 'gene_40', 'gene_41', 'gene_42', 'gene_43', 'gene_44', 'gene_45', 'gene_46', 'gene_47', 'gene_48', 'gene_49', 'gene_50', 'gene_51', 'gene_52', 'gene_53', 'gene_54', 'gene_55', 'gene_56', 'gene_57', 'gene_58', 'gene_59', 'gene_60', 'gene_61', 'gene_62', 'gene_63', 'gene_64', 'gene_65', 'gene_66', 'gene_67', 'gene_68', 'gene_69', 'gene_70', 'gene_71', 'gene_72', 'gene_73', 'gene_74', 'gene_75', 'gene_76', 'gene_77', 'gene_78', 'gene_79', 'gene_80', 'gene_81', 'gene_82', 'gene_83', 'gene_84', 'gene_85', 'gene_86', 'gene_87', 'gene_88', 'gene_89', 'gene_90', 'gene_91', 'gene_92', 'gene_93', 'gene_94', 'gene_95', 'gene_96', 'gene_97', 'gene_98', 'gene_99', 'sample']\n",
            "Data:\n",
            "     gene  sample_0  sample_1  sample_2  sample_3  sample_4  sample_5  sample_6  sample_7  \\\n",
            "0  gene_0  0.955679  0.538092  0.135685  0.490386  0.195520  0.097568  0.361440  0.084530   \n",
            "1  gene_1  0.191353  0.457552  0.446475  0.931761  0.343317  0.054039  0.910178  0.872918   \n",
            "2  gene_2  0.029414  0.968648  0.540229  0.471411  0.803783  0.120835  0.601292  0.426831   \n",
            "3  gene_3  0.991870  0.608980  0.151526  0.967035  0.893117  0.103368  0.903667  0.486883   \n",
            "4  gene_4  0.807643  0.308436  0.213614  0.430831  0.722794  0.265862  0.461568  0.344960   \n",
            "\n",
            "   sample_8  ...  sample_10  sample_11  sample_12  sample_13  sample_14  sample_15  sample_16  \\\n",
            "0  0.863238  ...   0.249941   0.086317   0.924085   0.171861   0.887884   0.867466   0.735514   \n",
            "1  0.039604  ...   0.069449   0.537532   0.503612   0.931254   0.245816   0.983890   0.146307   \n",
            "2  0.176009  ...   0.663312   0.174483   0.461519   0.741305   0.209545   0.865869   0.978802   \n",
            "3  0.609844  ...   0.989942   0.724148   0.236790   0.274849   0.934124   0.990880   0.335095   \n",
            "4  0.512506  ...   0.094032   0.196887   0.289708   0.087525   0.955780   0.003975   0.747703   \n",
            "\n",
            "   sample_17  sample_18  sample_19  \n",
            "0   0.528807   0.035855   0.437248  \n",
            "1   0.508116   0.603582   0.482260  \n",
            "2   0.747214   0.910177   0.218662  \n",
            "3   0.535709   0.289182   0.472694  \n",
            "4   0.788139   0.421577   0.484318  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Dataset: cell_cycle\n",
            "Type: qualitative\n",
            "Features: ['cell', 'phase']\n",
            "Data:\n",
            "     cell phase\n",
            "0  cell_0     M\n",
            "1  cell_1    G1\n",
            "2  cell_2    G1\n",
            "3  cell_3     S\n",
            "4  cell_4    G1\n",
            "\n",
            "Dataset: protein_interaction\n",
            "Type: network\n",
            "Features: ['protein_0', 'protein_1', 'protein_2', 'protein_3', 'protein_4', 'protein_5', 'protein_6', 'protein_7', 'protein_8', 'protein_9']\n",
            "Data:\n",
            "     protein  protein_0  protein_1  protein_2  protein_3  protein_4  protein_5  protein_6  \\\n",
            "0  protein_0          1          0          0          1          0          1          1   \n",
            "1  protein_1          1          0          1          0          1          0          0   \n",
            "2  protein_2          0          1          1          1          1          1          0   \n",
            "3  protein_3          1          1          0          0          1          0          1   \n",
            "4  protein_4          1          1          0          1          1          1          1   \n",
            "\n",
            "   protein_7  protein_8  protein_9  \n",
            "0          1          1          0  \n",
            "1          1          0          1  \n",
            "2          1          0          1  \n",
            "3          1          1          1  \n",
            "4          0          1          1  \n",
            "\n",
            "Dataset: tcga_brca\n",
            "Type: quantitative\n",
            "Features: ['gene_0', 'gene_1', 'gene_2', 'gene_3', 'gene_4', 'gene_5', 'gene_6', 'gene_7', 'gene_8', 'gene_9', 'gene_10', 'gene_11', 'gene_12', 'gene_13', 'gene_14', 'gene_15', 'gene_16', 'gene_17', 'gene_18', 'gene_19', 'gene_20', 'gene_21', 'gene_22', 'gene_23', 'gene_24', 'gene_25', 'gene_26', 'gene_27', 'gene_28', 'gene_29', 'gene_30', 'gene_31', 'gene_32', 'gene_33', 'gene_34', 'gene_35', 'gene_36', 'gene_37', 'gene_38', 'gene_39', 'gene_40', 'gene_41', 'gene_42', 'gene_43', 'gene_44', 'gene_45', 'gene_46', 'gene_47', 'gene_48', 'gene_49', 'gene_50', 'gene_51', 'gene_52', 'gene_53', 'gene_54', 'gene_55', 'gene_56', 'gene_57', 'gene_58', 'gene_59', 'gene_60', 'gene_61', 'gene_62', 'gene_63', 'gene_64', 'gene_65', 'gene_66', 'gene_67', 'gene_68', 'gene_69', 'gene_70', 'gene_71', 'gene_72', 'gene_73', 'gene_74', 'gene_75', 'gene_76', 'gene_77', 'gene_78', 'gene_79', 'gene_80', 'gene_81', 'gene_82', 'gene_83', 'gene_84', 'gene_85', 'gene_86', 'gene_87', 'gene_88', 'gene_89', 'gene_90', 'gene_91', 'gene_92', 'gene_93', 'gene_94', 'gene_95', 'gene_96', 'gene_97', 'gene_98', 'gene_99', 'patient']\n",
            "Data:\n",
            "     gene  patient_0  patient_1  patient_2  patient_3  patient_4  patient_5  patient_6  patient_7  \\\n",
            "0  gene_0   0.554085   0.742721   0.321314   0.167449   0.905469   0.453990   0.321033   0.211399   \n",
            "1  gene_1   0.764139   0.312659   0.352698   0.837779   0.385484   0.266587   0.978304   0.973204   \n",
            "2  gene_2   0.144165   0.017485   0.788706   0.067468   0.312445   0.723237   0.292356   0.650998   \n",
            "3  gene_3   0.610772   0.057156   0.511179   0.907845   0.841620   0.176459   0.263546   0.540333   \n",
            "4  gene_4   0.186453   0.831463   0.898996   0.061903   0.219917   0.423030   0.568561   0.847908   \n",
            "\n",
            "   patient_8  ...  patient_40  patient_41  patient_42  patient_43  patient_44  patient_45  \\\n",
            "0   0.624915  ...    0.121804    0.955877    0.782903    0.776665    0.696433    0.866922   \n",
            "1   0.539602  ...    0.230360    0.619829    0.563430    0.652555    0.891188    0.190830   \n",
            "2   0.624965  ...    0.714552    0.100382    0.250652    0.746114    0.257313    0.380640   \n",
            "3   0.034924  ...    0.672777    0.880918    0.116361    0.019189    0.486798    0.715082   \n",
            "4   0.813625  ...    0.672313    0.743315    0.016965    0.820007    0.331845    0.572034   \n",
            "\n",
            "   patient_46  patient_47  patient_48  patient_49  \n",
            "0    0.148541    0.792308    0.999420    0.749331  \n",
            "1    0.478702    0.191643    0.455790    0.257807  \n",
            "2    0.257054    0.338732    0.591086    0.061050  \n",
            "3    0.992963    0.032366    0.991514    0.372134  \n",
            "4    0.180210    0.802207    0.970049    0.574036  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}